from snakemake.utils import min_version, validate

min_version("3.2")

configfile: "config.yaml"
validate(config, schema="schemas/config.schema.yaml")

#cells = pd.read_csv(config["cells"], sep="\t").set_index("id", drop=False)
#validate(cells, schema="schemas/cells.schema.yaml")

# https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#combining-conda-package-management-with-containers
singularity: "docker://continuumio/miniconda3:latest"

rule all:
  input: []
  output: []
  params: []
  log: []
  benchmark: []
  message: ''
  threads: 1
  #resources: []
  #run: ''
  shell: 'echo hello world'

# TODO: what if reference or query is blank/invalid?
rule frankenfasta:
  input:
    reference=config['reference'],
    query='{sample_name}.fasta'
  output: '{sample_name}.frankenfasta'
  params:
    sample_name='{sample_name}'
  log: []
  benchmark: []
  message: ''
  #threads: 1
  #resources: []
  conda: "envs/mummer.yaml"
  #run: ''
  # nucmer [options] <Reference> <Query>
  # delta-filter [options] <deltafile>
  shell: '''
  nasp frankenfasta <(
    delta-filter -q -r -o 100 \
      <(nucmer --threads {threads} --delta /dev/stdout {input.reference} {input.query})
  ) > {output}
  '''


# envs/samtools.yaml
# channels:
#   - bioconda
# dependencies:
#   - samtools =1.9
rule samtools_index:
  input:
      "sorted_reads/{sample}.bam"
  output:
      "sorted_reads/{sample}.bam.bai"
  conda:
      "envs/samtools.yaml"
  shell:
      "samtools index {input}"

#include: "path/to/other.snakefile"


# onstart handler, that allows to add code that shall be only executed before the actual workflow execution (not on dryrun).
# Parameters defined in the cluster config file are now accessible in the job properties under the key “cluster”.
